export default {
  title: "58 Alternativas de cache en servidor",
  videoId: "WfCBWFMb7B4",
  notes: [
    { type: "subtitle", content: "ü§∑‚Äç Alternativas de cache en servidor" },
    {
      type: "text",
      content: "A nivel de Servidor tambi√©n contamos con distintas alternativas que podr√≠amos diferenciar en base a d√≥nde las ubicar√≠amos y, por supuesto, cada una de ellas nos ofrecer√° diferentes ventajas e inconvenientes"
    },
    { type: "subtitle", content: "1- Cach√© delante del Controller" },
    {
      type: "text", 
      content: "Esta opci√≥n implica situar una pieza por delante del Controller (Por ejemplo Varnish o Akamai), lo que entendemos como Proxys reversos. Tiene a favor que no necesitaremos picar nada para disponer de esta cach√©, pero por contra, al ser una pieza externa a nuestra aplicaci√≥n, estaremos perdiendo el control de lo que sucede en ella ü§î"
    },
    {
      type: "text",
      content: "A diferencia de lo que ve√≠amos con la cach√© de cliente no ser√° necesario que haya un primer cliente para que se cach√©e el contenido, de modo que podemos forzarla y que el primer acceso que recibamos ya se beneficie de ello (Especialmente √∫til cuando necesitamos que los scrapers recorran nuestro sitio web lo m√°s r√°pido posible), adem√°s de evitar saturaciones en sistemas de alta concurrencia"
    },
    { type: "subtitle", content: "2- Cach√© delante del Application Service" },
    {
      type: "text",
      content: "Otra opci√≥n que tenemos es llevar la gesti√≥n de la cach√© a un Middleware en el Controller o entre √©ste y el Application Service y que sea este middleware quien tenga cacheado el resultado de las Queries en un Redis u otro almacenamiento r√°pido."
    },
    {
      type: "text", 
      content: "El beneficio que nos aporta esta alternativa es poder centralizar en un punto concreto la cach√©, lo que a su vez tambi√©n ser√° un problema ya que el middleware se encargar√≠a de cachear todas las queries y gestionar la configuraci√≥n de cada una se hace mas tediosa ü§Ø"
    },
    {
      type: "text",
      content: "Por otra parte, a diferencia de lo que ve√≠amos en un proxy reverso, esta alternativa tampoco nos permite cachear directamente toda la respuesta (lo que nos ahorrar√≠a el coste computacional de generarla)"
    },
    { type: "subtitle", content: "3- Cach√© dentro del Application Service" },
    {
      type: "text",
      content: "Una tercera alternativa podr√≠a ser llevar la cach√© dentro del propio application service, no obstante consideramos que no estar√≠a bien contaminar el caso de uso con el concepto de cach√© ya que √©sta no es algo que pertenezca realmente a nuestro Dominio"
    },
    {
      type: "text",
      content: "Debemos considerar que si estamos generando esta l√≥gica en el caso de uso, seguramente se deba a que la infraestructura concreta que estamos utilizando va lenta, es decir, si esa l√≥gica resulta innecesaria en el momento en que cambiamos ese detalle de infraestructura nos vamos a encontrar en un escenario en el cual un detalle de implementaci√≥n est√° condicionando nuestro caso de uso ü§¶‚Äç‚ôÇÔ∏è"
    },
    { type: "subtitle", content: "4- Cach√© en la capa de Infraestructura" },
    {
      type: "text",
      content: "Esta alternativa supondr√≠a llevar esta l√≥gica a la propia capa de infraestructura (Por ejemplo utilzando un decorador de nuestra implementaci√≥n de MySQL) sin que el propio caso de uso se vea afectado y es la opci√≥n por la cual nos decantar√≠amos particularmente (entraremos en m√°s detalle en el siguiente video)"
    },
    { type: "subtitle", content: "¬øAlguna Duda?" },
    {
      type: "text",
      content: "Si tienes alguna duda sobre el contenido del video o quieres compartir alguna sugerencia no dudes en abrir una nueva discusi√≥n m√°s abajo üëáüëáüëá"
    },
    {
      type: "text",
      content: "¬°Nos vemos en el siguiente video: ‚úåÔ∏è Cache de servidor: Optimizar casos de uso sin ensuciar el dominio!"
    }
  ],
};
